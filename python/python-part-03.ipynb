{
 "metadata": {
  "name": "",
  "signature": "sha256:b25a18d7bab46ffb3ba59cf5cb74afb530361c8b3db1323994af7bcf7df83423"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# iPython, Regular Expressions, and Intro to Scientific Libraries (biopython, numpy, scipy)\n",
      "\n",
      "## Section 1 - Python Prompt Improved\n",
      "\n",
      "* iPython prompt is a more powerful interactive shell\n",
      "* Not installed by default in python but can be easily installed via easy_install, note the readline install issue\n",
      "* To run, just type `ipython` in the terminal:\n",
      "\n",
      "```\n",
      "bitnami@linux:~$ ipython\n",
      "Python 2.7.8 |Anaconda 2.0.1 (64-bit)| (default, Aug 21 2014, 18:22:21) \n",
      "Type \"copyright\", \"credits\" or \"license\" for more information.\n",
      "\n",
      "IPython 2.2.0 -- An enhanced Interactive Python.\n",
      "Anaconda is brought to you by Continuum Analytics.\n",
      "Please check out: http://continuum.io/thanks and https://binstar.org\n",
      "?         -> Introduction and overview of IPython's features.\n",
      "%quickref -> Quick reference.\n",
      "help      -> Python's own help system.\n",
      "object?   -> Details about 'object', use 'object??' for extra details.\n",
      "\n",
      "In [1]: \n",
      "```\n",
      "\n",
      "Note: To exit iPython, we can enter **`quit`** which is more conventient than **`quit()`** (still works though)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Section 2 - iPython Features\n",
      "\n",
      "* More helpful help via \"?\" (`help(len)` vs `len?`)\n",
      "  * plus the output stays inline so you can read it while trying to use the feature\n",
      "  * Also handy to find out the type of a variable\n",
      "* Super nifty tab-completion\n",
      "  * make a string variable like `a = 'Hello'`, then type `a + <Tab>`\n",
      "  * Also useful to figure out what methods are available for a variable or what modules are available to import\n",
      "* \"magic\" commands brought to you by the letter \"%\"\n",
      "  * Lots of useful ones, browse them using `lsmagic`\n",
      "  * A better `dir()` in `%who`\n",
      "  * Get you command history via `%hist` (also grep-able with -g). A great way to jumpstart a script.\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Section 3 - Regular Expressions\n",
      "\n",
      "* Love/hate relationship with Excel? Especially importing data.\n",
      "* Open data file:\n",
      "  * Note the mixed date formats\n",
      "  * Also, there are text fields like \"001\" that could get mangled to numbers \"1\".\n",
      "  * Perhaps we need to process the data or import into a database\n",
      "* How to clean up this data?\n",
      "  * We could use a couple approaches: sed/awk, text editor w/find/replace, Python, Perl\n",
      "  * Most of these approaches would have one thing in common: Regular expressions\n",
      "* What is a regular expression & why learn them?\n",
      "  * Funny name: In the 50s, mathematician Stephen Kleene found that regular language is constructed by patterns, called regular expressions\n",
      "  * Regular expressions are a collection of patterns we can use to process nearly any text\n",
      "  * Regular expressions are contructed using a combination of metacharacters: characters with a special meaning used to concisely define patterns\n",
      "  * Knowing regex can be valuable in in many tools besides Python. Unix commands, good text editors. May not even have to write any code to solve certain data munging problems.\n",
      "\n",
      "### Goal: Get data from 3 sites into a uniform format\n",
      "\n",
      "Look at the data from our 3 sites. Each site recorded background evil at different times, and each record should have 3 items:\n",
      "\n",
      "* site name\n",
      "* date\n",
      "* data measurement (in millivaders)\n",
      "\n",
      "However, as is common with data sets from different locations, the data format is inconsistent between sites. We need to get the data into a common format to import into our database to save the world!\n",
      "\n",
      "Look at the 3 data files, noting the differences. They have different delimiters, different date formats, etc.\n",
      "\n",
      "We want all the date in a CSV format like:\n",
      "\n",
      "```\n",
      "year,month,date,site,measurement\n",
      "```\n",
      "\n",
      "And, we want all the months and days in numeric format with no leading zeroes."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Online Regex Tool\n",
      "\n",
      "Before we begin using regular expressions in Python let's have an overview using the online regex tool:\n",
      "\n",
      "https://www.regex101.com/#python"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Example 1 - Words with spelling variations\n",
      "\n",
      "Goal: Match spelling variations of the color \"gray\"\n",
      "\n",
      "In the \"TEST STRING\" text box type\n",
      "\n",
      "```\n",
      "grey gray\n",
      "```\n",
      "\n",
      "Now, in the \"REGULAR EXPRESSION\" input field type the regular expression:\n",
      "\n",
      "```\n",
      "grey\n",
      "```\n",
      "\n",
      "Notice the first \"grey\" in the text string box is highlighted. Also, note the helpful explanation and match information on the right hand side. There are no \"match groups\" extracted, even though we found a match. To extract and save our match, we can wrap our regex in `( )`:\n",
      "\n",
      "```\n",
      "(grey)\n",
      "```\n",
      "\n",
      "Ok, now we extracted our match, now let's match the other variation. Since the 2 only differ on the 3rd letter, we can use the single character wildcard \".\":\n",
      "\n",
      "```\n",
      "(gr.y)\n",
      "```\n",
      "\n",
      "But, that still just matches the first word. We need to perform a global search. To do this, we need to use a regex modifier. Type the letter \"g\" in the 2nd input field. Now, our regex matches both.\n",
      "\n",
      "But, this would also match mispellings. To prove this, edit our TEST STRING to:\n",
      "\n",
      "```\n",
      "grey gray grzy\n",
      "```\n",
      "\n",
      "Now, we have 3 matches. Eeks, that's not good! Let's fix this by modifying our regex to match only \"e\" or \"a\":\n",
      "\n",
      "\n",
      "```\n",
      "(gr[ea]y)\n",
      "```\n",
      "\n",
      "Nice, that avoids our mispelled word. The square brackets match a single character matching any character included in the list (very similar to the list syntax in Python)\n",
      "\n",
      "Ok, let's try another word with variations. Replace the TEST STRING with:\n",
      "\n",
      "```\n",
      "color colour\n",
      "```\n",
      "\n",
      "Our \"or\" approach won't work here, but we can use the optional character, \"?\", also known as the \"zero or one\" metacharacter:\n",
      "\n",
      "```\n",
      "colou?r\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Example 2 - Matching words\n",
      "\n",
      "Goal: Match all words. A word is any collection of alphanumeric characters (A-z, a-z, 0-9).\n",
      "\n",
      "In the \"TEST STRING\" text box type\n",
      "\n",
      "```\n",
      "red green gray blue yellow\n",
      "```\n",
      "\n",
      "Use the regex:\n",
      "\n",
      "```\n",
      "\\w\n",
      "```\n",
      "\n",
      "The backslash is our familiar escape character, and the \"w\" represents any alphanumeric character. The result seems ok, but if we add our capture `( )` syntax, we see we are actually matching all the characters and not the words. Let's add the \"one or more\" metacharacter:\n",
      "\n",
      "```\n",
      "\\w+\n",
      "```\n",
      "\n",
      "Notice this works even if our text spans more than one line. But, what if we only want certain words. Let's match all words beginning with the letter \"r\", we'll start by trying to just add the letter \"r\" to the beggining of the last regex:\n",
      "\n",
      "```\n",
      "r\\w+\n",
      "```\n",
      "\n",
      "Oops, we matched all strings beginning with \"r\", even if they are part of a word. We can use the the word boundary anchor, \"\\b\" to make sure our match is a whole word. And, we want to use parenthesis to avoid having the word boundary as part of our extracted result.:\n",
      "\n",
      "```\n",
      "\\b(r\\w+)\n",
      "```\n",
      "\n",
      "That's better. What about any word starting with letters \"a\" through \"m\":\n",
      "\n",
      "```\n",
      "\\b([a-m]\\w+)\n",
      "```\n",
      "\n",
      "Great, but there's still a problem. This wouldn't work with single character words, like \"a\" . For that we would want the \"zero or more\" metacharacter:\n",
      "\n",
      "```\n",
      "\\b([a-m]\\w*)\n",
      "```\n",
      "\n",
      "What about all the words containing a 'y'?\n",
      "\n",
      "```\n",
      "\\w*y\\w*\n",
      "```\n",
      "\n",
      "Ok, what about all the 4 character words? We can use the curly brace to quantify the number of characters:\n",
      "\n",
      "```\n",
      "\\b\\w{4}\\b\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Example 3 - Matching Numbers with Data from Site 1\n",
      "\n",
      "Copy and paste the data for site 1 into the \"TEST STRING\" text box. \n",
      "\n",
      "```\n",
      "Baker 1\t2009-11-17\t1223.0\n",
      "Baker 1\t2010-06-24\t1122.7\n",
      "Baker 2\t2009-07-24\t2819.0\n",
      "Baker 2\t2010-08-25\t2971.6\n",
      "Baker 1\t2011-01-05\t1410.0\n",
      "Baker 2\t2010-09-04\t4671.6\n",
      "Baker 2\t2012-02-25\t1099.0\n",
      "Baker 1\t2013-01-01\t950.9\n",
      "Baker 1\t2012-07-23\t2000.0\n",
      "Baker 2\t2013-08-22\t3500.4\n",
      "Baker 2\t2014-01-02\t4510.1\n",
      "```\n",
      "\n",
      "Now, let's start by trying to extract the date, starting with the year.\n",
      "\n",
      "```\n",
      "(2009)\n",
      "```\n",
      "\n",
      "Looks good, we matched both occurences of \"2009\". Now, let's try matching all the years, and instead of using the wildcard character \".\", we'll use a new metacharacter to match single digits, \"\\d\". Since it looks like all the years are after 2000, we'll try 2 wildcards for the last 2 digits:\n",
      "\n",
      "```\n",
      "(20\\d\\d)\n",
      "```\n",
      "\n",
      "That worked, but we also matched one of the data values \"2000.0\". The dates include dashes, so we can use that to avoid matching any values. We'll include the regex to cover the month and day as well:\n",
      "\n",
      "```\n",
      "(20\\d\\d)-(\\d\\d)-(\\d\\d)\n",
      "````\n",
      "\n",
      "Great, now let's parse the rest of the line to get all of our fields, starting with the site name. We'll use a tab character to distinguish the site name at the beginning of the line:\n",
      "\n",
      "```\n",
      "^(.+)\\t\n",
      "```\n",
      "\n",
      "Notice the caret, it is another anchor character denoting the beginning of the line. For the online tool, we need to add the multiline global option, \"m\", so that it knows to allow the caret to match the beginning of every line, not just the first one.\n",
      "\n",
      "We used the wild card with the one or more quantifier, surrounded in parenthesis. We didn't want just a word because our site name has a space in it. Finally, we used a tab character to end the wild card search.\n",
      "\n",
      "Next, let's tackle the value of evil-ness. It looks like a regular float, which means there's a decimal character. But, the \".\" character is already used as a wild card. Anyone know what we can do here? Yep, we can use the backslash to escape the special character's meaning and match a literal \".\":\n",
      "\n",
      "```\n",
      "\\t(\\d+\\.?\\d*)$\n",
      "```\n",
      "\n",
      "We've also handled the case where the value may not have a decimal, making it optional. And in that case the 2nd \"\\d\" covering the fractional part would be absent so we use the zero or more quantifier. Finally, we've used the end of line anchor as another data validation technique.\n",
      "\n",
      "Looks like we have all of our parts, let's put it all together and get all the values we need from the data record:\n",
      "\n",
      "```\n",
      "^(.*)\\t(20\\d\\d)-(\\d\\d)-(\\d\\d)\\t(\\d+\\.?\\d*)$\n",
      "```\n",
      "\n",
      "Ok, let's take this to Python and see how regex works there."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next, create a dummy string:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "s = \"The cat in the hat.\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Use the `search()` method to find 3-letter words ending in \"at\":"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "re.search('(\\wat)', s)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "<_sre.SRE_Match at 0x7f31e6b05198>"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It did something, but what exactly? When a match is found, search() returns an SRE_Match object. If nothing is found, search() returns None. In this way it can be useful in conjunction with an if statement. But, for now let's save the object and see what we can do with it:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "result = re.search('(\\wat)', s)\n",
      "result.groups()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "('cat',)"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We should've matched both `cat` and `hat` but we just got the first match. Remember, the online tool had the same issue? We need to add a global search option, but how? Let's ask iPython for some help:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "```\n",
      "re.search?\n",
      "\n",
      "Type:       function\n",
      "String Form:<function search at 0x7f31fd253c80>\n",
      "File:       /usr/lib/python2.7/re.py\n",
      "Definition: re.search(pattern, string, flags=0)\n",
      "Docstring:\n",
      "Scan through string looking for a match to the pattern, returning\n",
      "a match object, or None if no match was found.\n",
      "```\n",
      "\n",
      "The flags option may work, but unfortunately Python does not have a \"global\" flag. The flags it does have are:\n",
      "\n",
      "```\n",
      "syntax    long syntax    meaning\n",
      "re.I      re.IGNORECASE  ignore case.\n",
      "re.M      re.MULTILINE   make begin/end {^, $} consider each line.\n",
      "re.S      re.DOTALL      make . match newline too.\n",
      "re.U      re.UNICODE     make {\\w, \\W, \\b, \\B} follow Unicode rules.\n",
      "re.L      re.LOCALE      make {\\w, \\W, \\b, \\B} follow locale.\n",
      "re.X      re.VERBOSE     allow comment in regex.\n",
      "```\n",
      "\n",
      "To find all the matches we must use the findall() method:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "re.findall('(\\wat)', s)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "['cat', 'hat']"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "That's better! However, as you can see, `findall()` does not return an SRE_Match object, but rather a simple list. Good to know, but let's continue with the search method using a new string that represents one of our data records:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "s = \"Baker 12009-11-171223.0\"\n",
      "print s"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Baker 12009-11-171223.0\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Wait, what happened to our tabs? Simply copying and pasting will not work within the iPython prompt. If we really want to copy and paste, we can use the iPython magic command `%paste`, but there's a caveat: It returns a list for every line in your clipboard. And, it doesn't work in the iPython notebook, not that you should be using that now anyway!!!\n",
      "\n",
      "Let's try it out, copy the first data record from site 1 text file, and then enter the following into the iPython prompt:\n",
      "\n",
      "```\n",
      "%paste s\n",
      "```\n",
      "\n",
      "Now, the variable `s` is a list with one element. No problem, let's just re-define the variable using itself:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# recreated here b/c the notebook can't use %paste\n",
      "s = [u'Baker 1\\t2009-11-17\\t1223.0']\n",
      "print s\n",
      "s = s[0]\n",
      "print s"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[u'Baker 1\\t2009-11-17\\t1223.0']\n",
        "Baker 1\t2009-11-17\t1223.0\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ok, back to the search method. Let's use the full regex we developed in the online tool on this record. First let's save our pattern:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pattern = '^(.*)\\t(20\\d\\d)-(\\d\\d)-(\\d\\d)\\t(\\d+\\.?\\d*)$'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Then, search our text string using the pattern, remembering to save the result:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "match = re.search(pattern, s)\n",
      "print match"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<_sre.SRE_Match object at 0x7f31f689ad20>\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Hey, we didn't get `None` so we did something right! Let examine our catch using `groups()`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "match.groups()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 29,
       "text": [
        "(u'Baker 1', u'2009', u'11', u'17', u'1223.0')"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Looks, good. And, we can get an individual group using the `group()` method by specifying a group number. However, `group(0)` doesn't give the first match, but rather the entire match. The higher group numbers are directly related to the number of captured strings we have, the parts that match within the `( )`. I warned you that this module wasn't intuitive. Let's examine:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print match.group(0)\n",
      "print match.group(1)\n",
      "print match.group(2)\n",
      "print match.group(3)\n",
      "print match.group(4)\n",
      "print match.group(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Baker 1\t2009-11-17\t1223.0\n",
        "Baker 1\n",
        "2009\n",
        "11\n",
        "17\n",
        "1223.0\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that we've got a handle on how `re` works, let's start writing a script to parse the site 1 data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Regex Script - Version 1\n",
      "\n",
      "We'll carry on from the previous script session and utilize fileinput. Open nano and enter the following:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import fileinput\n",
      "import re\n",
      "\n",
      "for line in fileinput.input():\n",
      "    match = re.search('^(.*)\\t(20\\d\\d)-(\\d\\d)-(\\d\\d)\\t(\\d+\\.?\\d*)$', line)\n",
      "    \n",
      "    if match:\n",
      "        fields = [\n",
      "            match.group(2),  # year\n",
      "            match.group(3),  # month\n",
      "            match.group(4),  # day\n",
      "            match.group(1),  # site\n",
      "            match.group(5)   # value\n",
      "        ]\n",
      "        \n",
      "        print ','.join(fields)\n",
      "    else:\n",
      "        print \"Line {} did not match!\".format(fileinput.lineno())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Save the script as `save_the_world_v1.py` and run it with the site 1 text file:\n",
      "\n",
      "```\n",
      "python save_the_world_v1.py data-part-03/notebook-1.txt\n",
      "```\n",
      "\n",
      "The output should be:\n",
      "\n",
      "```\n",
      "Line 1 did not match!\n",
      "2009,11,17,Baker 1,1223.0\n",
      "2010,06,24,Baker 1,1122.7\n",
      "2009,07,24,Baker 2,2819.0\n",
      "2010,08,25,Baker 2,2971.6\n",
      "2011,01,05,Baker 1,1410.0\n",
      "2010,09,04,Baker 2,4671.6\n",
      "2012,02,25,Baker 2,1099.0\n",
      "2013,01,01,Baker 1,950.9\n",
      "2012,07,23,Baker 1,2000.0\n",
      "2013,08,22,Baker 2,3500.4\n",
      "2014,01,02,Baker 2,4510.1\n",
      "```\n",
      "\n",
      "It works! We have the first site's data in the format we want. But, the first line didn't match because it is a header row. We'll take care of that in version 2, but let's also re-factor the bulk of the work into a function:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import fileinput\n",
      "import re\n",
      "\n",
      "def parse_record(record_string):\n",
      "    '''\n",
      "    Return formatted data record as (Y, M, D, site, value) or None\n",
      "    '''\n",
      "\n",
      "    # each pattern is a tuple, with the regex as the first value, \n",
      "    # then the matches in the order we would like:\n",
      "    # year, month, day, site, value\n",
      "    patterns = [\n",
      "        ( \n",
      "            '^(.*)\\t(20\\d\\d)-(\\d\\d)-(\\d\\d)\\t(\\d+\\.?\\d*)$',\n",
      "            2, 3, 4, 1, 5\n",
      "        )\n",
      "    ]\n",
      "    \n",
      "    for pattern, y, m, d, s, v in patterns:\n",
      "        match = re.search(pattern, record_string)\n",
      "        if match:\n",
      "            return [\n",
      "                match.group(y), \n",
      "                match.group(m), \n",
      "                match.group(d), \n",
      "                match.group(s), \n",
      "                match.group(v)\n",
      "            ]\n",
      "    \n",
      "    return None\n",
      "\n",
      "for line in fileinput.input():\n",
      "    if fileinput.isfirstline():\n",
      "        continue\n",
      "    fields = parse_record(line)\n",
      "    print fields"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, we have our code organized, and it's easy to add new patterns. Just add a new tuple to our patterns array, and throw as many files as you want as arguments to the script. Let's look at the pattern for site 2. Back to the online tool.\n",
      "\n",
      "Our old pattern no longer works, so we'll need to create a new one. One obvious difference: this site uses a backslash for a delimiter instead of a tab character. Let's isolate the first field, the site:\n",
      "\n",
      "```\n",
      "^([\\w|\\s]+)/\n",
      "```\n",
      "\n",
      "Starting at the beginning of a line, match one or more word or space characters. We know from the first text file that there might be spaces, perhaps we could stregthen the first regex? With regex, there's always more than one way to solve a problem. Anyway let's tackle the new date format:\n",
      "\n",
      "```\n",
      "^([\\w|\\s]+)/(\\w+)\\s*(\\d+),?\\s*(20\\d\\d)\n",
      "```\n",
      "\n",
      "Breaking this down. After the \"/\" delimiter, there should be one or more word characters for the month name. Then, maybe there's a space (zero or more). Next, we should find one or more digits for the day of the month, followed by an optional comma and maybe some more space (zero or more). Finally, we should find a 4 digit year between 2000 and 2099.\n",
      "\n",
      "This works, so let's add the final delimiter and get our value:\n",
      "\n",
      "```\n",
      "^([\\w|\\s]+)/(\\w+)\\s*(\\d+),?\\s*(20\\d\\d)/(\\d+\\.?\\d*)$\n",
      "```\n",
      "\n",
      "Looks like this works. Let's plug it into our script as a new pattern, save a version 3, and run it against both files. Note the match order is different for this pattern:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import fileinput\n",
      "import re\n",
      "\n",
      "def parse_record(record_string):\n",
      "    '''\n",
      "    Return formatted data record as (Y, M, D, site, value) or None\n",
      "    '''\n",
      "\n",
      "    # each pattern is a tuple, with the regex as the first value, \n",
      "    # then the matches in the order we would like:\n",
      "    # year, month, day, site, value\n",
      "    patterns = [\n",
      "        ( \n",
      "            '(.*)\\t(20\\d\\d)-(\\d\\d)-(\\d\\d)\\t(\\d+\\.?\\d*)',\n",
      "            2, 3, 4, 1, 5\n",
      "        ),\n",
      "        (\n",
      "            '^([\\w|\\s]+)/(\\w+)\\s*(\\d+),?\\s*(20\\d\\d)/(\\d+\\.?\\d*)$',\n",
      "            4, 2, 3, 1, 5\n",
      "        )\n",
      "    ]\n",
      "    \n",
      "    for pattern, y, m, d, s, v in patterns:\n",
      "        match = re.search(pattern, record_string)\n",
      "        if match:\n",
      "            return [\n",
      "                match.group(y), \n",
      "                match.group(m), \n",
      "                match.group(d), \n",
      "                match.group(s), \n",
      "                match.group(v)\n",
      "            ]\n",
      "    \n",
      "    return None\n",
      "\n",
      "for line in fileinput.input():\n",
      "    if fileinput.isfirstline():\n",
      "        continue\n",
      "    fields = parse_record(line)\n",
      "    print fields"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We successfully parsed all the data, but we wanted the months in numeric format. In version 4, let's convert the month abbreviations to numbers:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import fileinput\n",
      "import re\n",
      "\n",
      "def parse_record(record_string):\n",
      "    '''\n",
      "    Return formatted data record as (Y, M, D, site, value) or None\n",
      "    '''\n",
      "    \n",
      "    month_conversions = {\n",
      "        \"Jan\": 1,\n",
      "        \"Feb\": 2,\n",
      "        \"Mar\": 3,\n",
      "        \"Apr\": 4,\n",
      "        \"May\": 5,\n",
      "        \"Jun\": 6,\n",
      "        \"Jul\": 7,\n",
      "        \"Aug\": 8,\n",
      "        \"Sep\": 9,\n",
      "        \"Oct\": 10,\n",
      "        \"Nov\": 11,\n",
      "        \"Dec\": 12\n",
      "    }\n",
      "\n",
      "    # each pattern is a tuple, with the regex as the first value, \n",
      "    # then the matches in the order we would like:\n",
      "    # year, month, day, site, value\n",
      "    patterns = [\n",
      "        ( \n",
      "            '(.*)\\t(20\\d\\d)-(\\d\\d)-(\\d\\d)\\t(\\d+\\.?\\d*)',\n",
      "            2, 3, 4, 1, 5\n",
      "        ),\n",
      "        (\n",
      "            '^([\\w|\\s]+)/(\\w+)\\s*(\\d+),?\\s*(20\\d\\d)/(\\d+\\.?\\d*)$',\n",
      "            4, 2, 3, 1, 5\n",
      "        )\n",
      "    ]\n",
      "    \n",
      "    for pattern, y, m, d, s, v in patterns:\n",
      "        match = re.search(pattern, record_string)\n",
      "        if match:\n",
      "            if match.group(m)[0:3] in month_conversions.keys():\n",
      "                month = month_conversions[match.group(m)[0:3]]\n",
      "            else:\n",
      "                month = match.group(m)\n",
      "            \n",
      "            return [\n",
      "                match.group(y), \n",
      "                month, \n",
      "                match.group(d), \n",
      "                match.group(s), \n",
      "                match.group(v)\n",
      "            ]\n",
      "    \n",
      "    return None\n",
      "\n",
      "for line in fileinput.input():\n",
      "    if fileinput.isfirstline():\n",
      "        continue\n",
      "    fields = parse_record(line)\n",
      "    print fields"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And we need to convert the first file's months to numbers instead of strings, along with the year and day of the month. We need to convert the value to float as well. Let's create a version 5:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import fileinput\n",
      "import re\n",
      "\n",
      "def parse_record(record_string):\n",
      "    '''\n",
      "    Return formatted data record as (Y, M, D, site, value) or None\n",
      "    '''\n",
      "    \n",
      "    month_conversions = {\n",
      "        \"Jan\": 1,\n",
      "        \"Feb\": 2,\n",
      "        \"Mar\": 3,\n",
      "        \"Apr\": 4,\n",
      "        \"May\": 5,\n",
      "        \"Jun\": 6,\n",
      "        \"Jul\": 7,\n",
      "        \"Aug\": 8,\n",
      "        \"Sep\": 9,\n",
      "        \"Oct\": 10,\n",
      "        \"Nov\": 11,\n",
      "        \"Dec\": 12\n",
      "    }\n",
      "\n",
      "    # each pattern is a tuple, with the regex as the first value, \n",
      "    # then the matches in the order we would like:\n",
      "    # year, month, day, site, value\n",
      "    patterns = [\n",
      "        ( \n",
      "            '(.*)\\t(20\\d\\d)-(\\d\\d)-(\\d\\d)\\t(\\d+\\.?\\d*)',\n",
      "            2, 3, 4, 1, 5\n",
      "        ),\n",
      "        (\n",
      "            '^([\\w|\\s]+)/(\\w+)\\s*(\\d+),?\\s*(20\\d\\d)/(\\d+\\.?\\d*)$',\n",
      "            4, 2, 3, 1, 5\n",
      "        )\n",
      "    ]\n",
      "    \n",
      "    for pattern, y, m, d, s, v in patterns:\n",
      "        match = re.search(pattern, record_string)\n",
      "        if match:\n",
      "            if match.group(m)[0:3] in month_conversions.keys():\n",
      "                month = month_conversions[match.group(m)[0:3]]\n",
      "            else:\n",
      "                month = int(match.group(m))\n",
      "            \n",
      "            return [\n",
      "                int(match.group(y)), \n",
      "                month, \n",
      "                int(match.group(d)), \n",
      "                match.group(s), \n",
      "                float(match.group(v))\n",
      "            ]\n",
      "    \n",
      "    return None\n",
      "\n",
      "for line in fileinput.input():\n",
      "    if fileinput.isfirstline():\n",
      "        continue\n",
      "    fields = parse_record(line)\n",
      "    print fields"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Finally, let's save our output to a file:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import fileinput\n",
      "import re\n",
      "\n",
      "def parse_record(record_string):\n",
      "    '''\n",
      "    Return formatted data record as (Y, M, D, site, value) or None\n",
      "    '''\n",
      "    \n",
      "    month_conversions = {\n",
      "        \"Jan\": 1,\n",
      "        \"Feb\": 2,\n",
      "        \"Mar\": 3,\n",
      "        \"Apr\": 4,\n",
      "        \"May\": 5,\n",
      "        \"Jun\": 6,\n",
      "        \"Jul\": 7,\n",
      "        \"Aug\": 8,\n",
      "        \"Sep\": 9,\n",
      "        \"Oct\": 10,\n",
      "        \"Nov\": 11,\n",
      "        \"Dec\": 12\n",
      "    }\n",
      "\n",
      "    # each pattern is a tuple, with the regex as the first value, \n",
      "    # then the matches in the order we would like:\n",
      "    # year, month, day, site, value\n",
      "    patterns = [\n",
      "        ( \n",
      "            '(.*)\\t(20\\d\\d)-(\\d\\d)-(\\d\\d)\\t(\\d+\\.?\\d*)',\n",
      "            2, 3, 4, 1, 5\n",
      "        ),\n",
      "        (\n",
      "            '^([\\w|\\s]+)/(\\w+)\\s*(\\d+),?\\s*(20\\d\\d)/(\\d+\\.?\\d*)$',\n",
      "            4, 2, 3, 1, 5\n",
      "        )\n",
      "    ]\n",
      "    \n",
      "    for pattern, y, m, d, s, v in patterns:\n",
      "        match = re.search(pattern, record_string)\n",
      "        if match:\n",
      "            if match.group(m)[0:3] in month_conversions.keys():\n",
      "                month = month_conversions[match.group(m)[0:3]]\n",
      "            else:\n",
      "                month = int(match.group(m))\n",
      "            \n",
      "            return [\n",
      "                int(match.group(y)), \n",
      "                month, \n",
      "                int(match.group(d)), \n",
      "                match.group(s), \n",
      "                float(match.group(v))\n",
      "            ]\n",
      "    \n",
      "    return None\n",
      "\n",
      "output = open('output.csv', 'w')\n",
      "\n",
      "for line in fileinput.input():\n",
      "    if fileinput.isfirstline():\n",
      "        continue\n",
      "    fields = parse_record(line)\n",
      "    if fields:\n",
      "        output.write(','.join([str(f) for f in fields]))\n",
      "        output.write('\\n')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}