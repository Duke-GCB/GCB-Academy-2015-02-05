{
 "metadata": {
  "name": "",
  "signature": "sha256:1c4daafad51546fc573ad806c8963ea274fec01075333ff1a48af0abf98fa224"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "# iPython and Regular Expressions\n",
      "\n",
      "## Section 1 - Python Prompt Improved\n",
      "\n",
      "* iPython prompt is a more powerful interactive shell\n",
      "* Not installed by default in python but can be easily installed via easy_install, note the readline install issue\n",
      "* To run, just type `ipython` in the terminal:\n",
      "\n",
      "```\n",
      "bitnami@linux:~$ ipython\n",
      "Python 2.7.8 |Anaconda 2.0.1 (64-bit)| (default, Aug 21 2014, 18:22:21) \n",
      "Type \"copyright\", \"credits\" or \"license\" for more information.\n",
      "\n",
      "IPython 2.2.0 -- An enhanced Interactive Python.\n",
      "Anaconda is brought to you by Continuum Analytics.\n",
      "Please check out: http://continuum.io/thanks and https://binstar.org\n",
      "?         -> Introduction and overview of IPython's features.\n",
      "%quickref -> Quick reference.\n",
      "help      -> Python's own help system.\n",
      "object?   -> Details about 'object', use 'object??' for extra details.\n",
      "\n",
      "In [1]: \n",
      "```\n",
      "\n",
      "Note: To exit iPython, we can enter **`quit`** which is more conventient than **`quit()`** (still works though)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Section 2 - iPython Features\n",
      "\n",
      "* More helpful help via \"?\" (`help(len)` vs `len?`)\n",
      "  * plus the output stays inline so you can read it while trying to use the feature\n",
      "  * Also handy to find out the type of a variable\n",
      "* Super nifty tab-completion\n",
      "  * make a string variable like `a = 'Hello'`, then type `a + <Tab>`\n",
      "  * Also useful to figure out what methods are available for a variable or what modules are available to import\n",
      "* \"magic\" commands brought to you by the letter \"%\"\n",
      "  * Lots of useful ones, browse them using `lsmagic`\n",
      "  * A better `dir()` in `%who`\n",
      "  * Get you command history via `%hist` (also grep-able with -g). A great way to jumpstart a script.\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Section 3 - What are Regular Expressions & what can we do with them?\n",
      "\n",
      "* Love/hate relationship with Excel? Especially importing data. (ever had a string like \"001\" convert to a number?)\n",
      "* Open data file:\n",
      "  * Note the mixed date formats\n",
      "  * Also, the delimiters are different: commas vs spaces\n",
      "  * Perhaps we need to process the data or import into a database\n",
      "* How to clean up this data?\n",
      "  * We could use a couple approaches: sed/awk, text editor w/find/replace, Python, Perl\n",
      "  * Most of these approaches would have one thing in common: Regular expressions\n",
      "* What is a regular expression & why learn them?\n",
      "  * Funny name: In the 50s, mathematician Stephen Kleene found that regular language is constructed by patterns, called regular expressions\n",
      "  * Regular expressions are a collection of patterns we can use to process nearly any text\n",
      "  * Regular expressions are contructed using a combination of metacharacters: characters with a special meaning used to concisely define patterns\n",
      "  * Knowing regex can be valuable in in many tools besides Python. Unix commands, good text editors. May not even have to write any code to solve certain data munging problems.\n",
      "\n",
      "### Goal: Get data from 2 notebooks into a uniform format\n",
      "\n",
      "Look at the data from our 2 notebooks. Each contains records measureing background evil at different times, and each record should have 3 items:\n",
      "\n",
      "* site name\n",
      "* date\n",
      "* data measurement (in millivaders)\n",
      "\n",
      "However, as is common with data sets from different locations, the data format is inconsistent between notebooks. We need to get the data into a common format to import into our database to save the world!\n",
      "\n",
      "Look at the 2 data files, noting the differences. They have different delimiters, different date formats, etc.\n",
      "\n",
      "We want all the date in a CSV format like:\n",
      "\n",
      "```\n",
      "year,month,date,site,measurement\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Section 4 - Online Regex Tool\n",
      "\n",
      "Before we begin using regular expressions in Python let's have an overview using the online regex tool:\n",
      "\n",
      "https://www.regex101.com/#python"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Example 1 - Words with spelling variations\n",
      "\n",
      "Goal: Match spelling variations of the color \"gray\"\n",
      "\n",
      "In the \"TEST STRING\" text box type\n",
      "\n",
      "```\n",
      "grey gray\n",
      "```\n",
      "\n",
      "Now, in the \"REGULAR EXPRESSION\" input field type the regular expression:\n",
      "\n",
      "```\n",
      "grey\n",
      "```\n",
      "\n",
      "Notice the first \"grey\" in the text string box is highlighted. Also, note the helpful explanation and match information on the right hand side. There are no \"match groups\" extracted, even though we found a match. To extract and save our match, we can wrap our regex in `( )`:\n",
      "\n",
      "```\n",
      "(grey)\n",
      "```\n",
      "\n",
      "Ok, now we extracted our match, now let's match the other variation. Since the 2 only differ on the 3rd letter, we can use the single character wildcard \".\":\n",
      "\n",
      "```\n",
      "(gr.y)\n",
      "```\n",
      "\n",
      "But, that still just matches the first word. We need to perform a global search. To do this, we need to use a regex modifier. Type the letter \"g\" in the 2nd input field. Now, our regex matches both.\n",
      "\n",
      "But, this would also match mispellings. To prove this, edit our TEST STRING to:\n",
      "\n",
      "```\n",
      "grey gray grzy\n",
      "```\n",
      "\n",
      "Now, we have 3 matches. Eeks, that's not good! Let's fix this by modifying our regex to match only \"e\" or \"a\":\n",
      "\n",
      "\n",
      "```\n",
      "(gr[ea]y)\n",
      "```\n",
      "\n",
      "Nice, that avoids our mispelled word. The square brackets match a single character matching any character included in the list (very similar to the list syntax in Python)\n",
      "\n",
      "Ok, let's try another word with variations. Replace the TEST STRING with:\n",
      "\n",
      "```\n",
      "color colour\n",
      "```\n",
      "\n",
      "Our \"or\" approach won't work here, but we can use the optional character, \"?\", also known as the \"zero or one\" metacharacter:\n",
      "\n",
      "```\n",
      "colou?r\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Example 2 - Matching words\n",
      "\n",
      "Goal: Match all words. A word is any collection of alphanumeric characters (A-z, a-z, 0-9).\n",
      "\n",
      "In the \"TEST STRING\" text box type\n",
      "\n",
      "```\n",
      "red green gray blue yellow\n",
      "```\n",
      "\n",
      "Use the regex:\n",
      "\n",
      "```\n",
      "\\w\n",
      "```\n",
      "\n",
      "The backslash is our familiar escape character, and the \"w\" represents any alphanumeric character. The result seems ok, but if we add our capture `( )` syntax, we see we are actually matching all the characters and not the words. Let's add the \"one or more\" metacharacter:\n",
      "\n",
      "```\n",
      "\\w+\n",
      "```\n",
      "\n",
      "Notice this works even if our text spans more than one line. But, what if we only want certain words. Let's match all words beginning with the letter \"r\", we'll start by trying to just add the letter \"r\" to the beggining of the last regex:\n",
      "\n",
      "```\n",
      "r\\w+\n",
      "```\n",
      "\n",
      "Oops, we matched all strings beginning with \"r\", even if they are part of a word. We can use the the word boundary anchor, \"\\b\" to make sure our match is a whole word. And, we want to use parenthesis to avoid having the word boundary as part of our extracted result.:\n",
      "\n",
      "```\n",
      "\\b(r\\w+)\n",
      "```\n",
      "\n",
      "That's better. What about any word starting with letters \"a\" through \"m\":\n",
      "\n",
      "```\n",
      "\\b([a-m]\\w+)\n",
      "```\n",
      "\n",
      "Great, but there's still a problem. This wouldn't work with single character words, like \"a\" . For that we would want the \"zero or more\" metacharacter:\n",
      "\n",
      "```\n",
      "\\b([a-m]\\w*)\n",
      "```\n",
      "\n",
      "What about all the words containing a 'y'?\n",
      "\n",
      "```\n",
      "\\w*y\\w*\n",
      "```\n",
      "\n",
      "Ok, what about all the 4 character words? We can use the curly brace to quantify the number of characters:\n",
      "\n",
      "```\n",
      "\\b\\w{4}\\b\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Example 3 - Matching Numbers with Data from Site 1\n",
      "\n",
      "Copy and paste the data for site 1 into the \"TEST STRING\" text box. \n",
      "\n",
      "```\n",
      "Baker1 2009-11-17 1223.0\n",
      "Baker1 2010-06-24 1122.7\n",
      "Baker2 2009-07-24 2819.0\n",
      "Baker2 2010-08-25 2971.6\n",
      "Baker1 2011-01-05 1410.0\n",
      "Baker2 2010-09-04 4671.6\n",
      "Baker2 2012-02-25 1099.0\n",
      "Baker1 2013-01-01 950.9\n",
      "Baker1 2012-07-23 2000.0\n",
      "Baker2 2013-08-22 3500.4\n",
      "Baker2 2014-01-02 4510.1\n",
      "```\n",
      "\n",
      "Now, let's start by trying to extract the date, starting with the year.\n",
      "\n",
      "```\n",
      "(2009)\n",
      "```\n",
      "\n",
      "Looks good, we matched both occurences of \"2009\". Now, let's try matching all the years, and instead of using the wildcard character \".\", we'll use a new metacharacter to match single digits, \"\\d\". Since it looks like all the years are after 2000, we'll try 2 wildcards for the last 2 digits:\n",
      "\n",
      "```\n",
      "(20\\d\\d)\n",
      "```\n",
      "\n",
      "That worked, but we also matched one of the data values \"2000.0\". The dates include dashes, so we can use that to avoid matching any values. We'll include the regex to cover the month and day as well:\n",
      "\n",
      "```\n",
      "(20\\d\\d)-(\\d\\d)-(\\d\\d)\n",
      "````\n",
      "\n",
      "Great, now let's parse the rest of the line to get all of our fields, starting with the site name:\n",
      "\n",
      "```\n",
      "^(\\w+)\\s+\n",
      "```\n",
      "\n",
      "Notice the caret, it is another anchor character denoting the beginning of the line. For the online tool, we need to add the multiline global option, \"m\", so that it knows to allow the caret to match the beginning of every line, not just the first one.\n",
      "\n",
      "We used the word character with the one or more quantifier, surrounded in parenthesis. Finally, we used a space character to end the wild card search, and we use the one or more quantifier in case the delimiter is more than one space long.\n",
      "\n",
      "Next, let's tackle the value of evil-ness. It looks like a regular float, which means there's a decimal character. But, the \".\" character is already used as a wild card. Anyone know what we can do here? Yep, we can use the backslash to escape the special character's meaning and match a literal \".\":\n",
      "\n",
      "```\n",
      "\\s+(\\d+\\.?\\d*)$\n",
      "```\n",
      "\n",
      "We've also handled the case where the value may not have a decimal, making it optional. And in that case the 2nd \"\\d\" covering the fractional part would be absent so we use the zero or more quantifier. Finally, we've used the end of line anchor as another data validation technique.\n",
      "\n",
      "Looks like we have all of our parts, let's put it all together and get all the values we need from the data record:\n",
      "\n",
      "```\n",
      "^(\\w+)\\s+(20\\d\\d)-(\\d\\d)-(\\d\\d)\\s+(\\d+\\.?\\d*)$\n",
      "```\n",
      "\n",
      "Ok, let's switch back to the iPython prompt and see how regex works there."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Section 5 - Python's `re` module\n",
      "\n",
      "To use regular expressions in Python, we first need to import the `re` module:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next, create a dummy string:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "s = \"The cat in the hat.\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Use the `search()` method to find 3-letter words ending in \"at\":"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "re.search('(\\wat)', s)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "<_sre.SRE_Match at 0x10e34c468>"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It did something, but what exactly? When a match is found, search() returns an SRE_Match object. If nothing is found, search() returns None. In this way it can be useful in conjunction with an if statement. But, for now let's save the object and see what we can do with it:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "result = re.search('(\\wat)', s)\n",
      "result.groups()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "('cat',)"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We should've matched both `cat` and `hat` but we just got the first match. Remember, the online tool had the same issue? We need to add a global search option, but how? Let's ask iPython for some help:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "```\n",
      "re.search?\n",
      "\n",
      "Type:       function\n",
      "String Form:<function search at 0x7f31fd253c80>\n",
      "File:       /usr/lib/python2.7/re.py\n",
      "Definition: re.search(pattern, string, flags=0)\n",
      "Docstring:\n",
      "Scan through string looking for a match to the pattern, returning\n",
      "a match object, or None if no match was found.\n",
      "```\n",
      "\n",
      "The flags option may work, but unfortunately Python does not have a \"global\" flag. The flags it does have are:\n",
      "\n",
      "```\n",
      "syntax    long syntax    meaning\n",
      "re.I      re.IGNORECASE  ignore case.\n",
      "re.M      re.MULTILINE   make begin/end {^, $} consider each line.\n",
      "re.S      re.DOTALL      make . match newline too.\n",
      "re.U      re.UNICODE     make {\\w, \\W, \\b, \\B} follow Unicode rules.\n",
      "re.L      re.LOCALE      make {\\w, \\W, \\b, \\B} follow locale.\n",
      "re.X      re.VERBOSE     allow comment in regex.\n",
      "```\n",
      "\n",
      "To find all the matches we must use the findall() method:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "re.findall('(\\wat)', s)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "['cat', 'hat']"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "That's better! However, as you can see, `findall()` does not return an SRE_Match object, but rather a simple list. Good to know, but let's continue with the search method using a new string that represents one of our data records:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "s = \"Baker1 2009-11-17 1223.0\"\n",
      "print s"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Baker1 2009-11-17 1223.0\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's use the full regex we developed in the online tool on this record. First let's save our pattern:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pattern = '^(\\w+)\\s+(20\\d\\d)-(\\d\\d)-(\\d\\d)\\s+(\\d+\\.?\\d*)$'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Then, search our text string using the pattern, remembering to save the result:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "match = re.search(pattern, s)\n",
      "print match"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<_sre.SRE_Match object at 0x10dbd7760>\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Hey, we didn't get `None` so we did something right! Let examine our catch using `groups()`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "match.groups()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "('Baker1', '2009', '11', '17', '1223.0')"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Looks, good. And, we can get an individual group using the `group()` method by specifying a group number. However, `group(0)` doesn't give the first match, but rather the entire match. The higher group numbers are directly related to the number of captured strings we have, the parts that match within the `( )`. I warned you that this module wasn't intuitive. Let's examine:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print match.group(0)\n",
      "print match.group(1)\n",
      "print match.group(2)\n",
      "print match.group(3)\n",
      "print match.group(4)\n",
      "print match.group(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Baker1 2009-11-17 1223.0\n",
        "Baker1\n",
        "2009\n",
        "11\n",
        "17\n",
        "1223.0\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that we've got a handle on how `re` works, let's start writing a script to parse the site 1 data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Section 6 - Regex Script Version 1\n",
      "\n",
      "We'll carry on from the previous script session and utilize fileinput. Open nano and enter the following:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import fileinput\n",
      "import re\n",
      "\n",
      "for line in fileinput.input():\n",
      "    match = re.search('^(\\w+)\\s+(20\\d\\d)-(\\d\\d)-(\\d\\d)\\s+(\\d+\\.?\\d*)$', line)\n",
      "    \n",
      "    if match:\n",
      "        fields = [\n",
      "            match.group(2),  # year\n",
      "            match.group(3),  # month\n",
      "            match.group(4),  # day\n",
      "            match.group(1),  # site\n",
      "            match.group(5)   # value\n",
      "        ]\n",
      "        \n",
      "        print fields\n",
      "    else:\n",
      "        print \"Line {} did not match!\".format(fileinput.lineno())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Save the script as `save_the_world_v1.py` and run it with the site 1 text file:\n",
      "\n",
      "```\n",
      "python save_the_world_v1.py ../data-part-03/notebook-1.txt\n",
      "```\n",
      "\n",
      "The output should be:\n",
      "\n",
      "```\n",
      "Line 1 did not match!\n",
      "['2009', '11', '17', 'Baker1', '1223.0']\n",
      "['2010', '06', '24', 'Baker1', '1122.7']\n",
      "['2009', '07', '24', 'Baker2', '2819.0']\n",
      "['2010', '08', '25', 'Baker2', '2971.6']\n",
      "['2011', '01', '05', 'Baker1', '1410.0']\n",
      "['2010', '09', '04', 'Baker2', '4671.6']\n",
      "['2012', '02', '25', 'Baker2', '1099.0']\n",
      "['2013', '01', '01', 'Baker1', '950.9']\n",
      "['2012', '07', '23', 'Baker1', '2000.0']\n",
      "['2013', '08', '22', 'Baker2', '3500.4']\n",
      "['2014', '01', '02', 'Baker2', '4510.1']\n",
      "```\n",
      "\n",
      "It works! We have successfully parsed the first site's data. But, there are a couple things we need to fix. First, the output for each record is a list, we need to convert that into the CSV format we want. Also, the first line didn't match because it is a header row. We'll take care of both of these issues in version 2:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Section 7 - Regex Script Version 2\n",
      "\n",
      "* Convert output into the CSV format we want. \n",
      "* Skip the header line"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import fileinput\n",
      "import re\n",
      "\n",
      "for line in fileinput.input():\n",
      "    if fileinput.isfirstline():\n",
      "        continue\n",
      "    \n",
      "    match = re.search('^(\\w+)\\s+(20\\d\\d)-(\\d\\d)-(\\d\\d)\\s+(\\d+\\.?\\d*)$', line)\n",
      "    \n",
      "    if match:\n",
      "        fields = [\n",
      "            match.group(2),  # year\n",
      "            match.group(3),  # month\n",
      "            match.group(4),  # day\n",
      "            match.group(1),  # site\n",
      "            match.group(5)   # value\n",
      "        ]\n",
      "        \n",
      "        print \",\".join(fields)\n",
      "    else:\n",
      "        print \"Line {} did not match!\".format(fileinput.lineno())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We've added a check to avoid the header row using `fileinput.isfirstline()`. We've also introduced the `join()` function. \n",
      "\n",
      "### Save the script as `save_the_world_v2.py` and run it with the 1st notebook file:\n",
      "\n",
      "```\n",
      "python save_the_world_v2.py ../data-part-03/notebook-1.txt\n",
      "```\n",
      "\n",
      "The output should be:\n",
      "\n",
      "```\n",
      "2009,11,17,Baker1,1223.0\n",
      "2010,06,24,Baker1,1122.7\n",
      "2009,07,24,Baker2,2819.0\n",
      "2010,08,25,Baker2,2971.6\n",
      "2011,01,05,Baker1,1410.0\n",
      "2010,09,04,Baker2,4671.6\n",
      "2012,02,25,Baker2,1099.0\n",
      "2013,01,01,Baker1,950.9\n",
      "2012,07,23,Baker1,2000.0\n",
      "2013,08,22,Baker2,3500.4\n",
      "2014,01,02,Baker2,4510.1\n",
      "```\n",
      "\n",
      "That's better! Next, we will re-factor the bulk of the work into a function."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Section 8 - Regex Script Version 3\n",
      "\n",
      "* Move the record parsing logic into a function"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import fileinput\n",
      "import re\n",
      "\n",
      "def parse_record(record_string):\n",
      "    '''\n",
      "    Return formatted data record as (Y, M, D, site, value) or None\n",
      "    '''\n",
      "\n",
      "    match = re.search('^(\\w+)\\s+(20\\d\\d)-(\\d\\d)-(\\d\\d)\\s+(\\d+\\.?\\d*)$', record_string)\n",
      "    \n",
      "    if match:\n",
      "        return [\n",
      "            match.group(2),  # year\n",
      "            match.group(3),  # month\n",
      "            match.group(4),  # day\n",
      "            match.group(1),  # site\n",
      "            match.group(5)   # value\n",
      "        ]\n",
      "    \n",
      "    return None\n",
      "\n",
      "for line in fileinput.input():\n",
      "    if fileinput.isfirstline():\n",
      "        continue\n",
      "\n",
      "    fields = parse_record(line)\n",
      "\n",
      "    if fields:\n",
      "        print \",\".join(fields)\n",
      "    else:\n",
      "        print \"Line {} did not match!\".format(fileinput.lineno())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Save as `save_the_world_v3.py` and run against the first notebook file\n",
      "\n",
      "```\n",
      "python save_the_world_v3.py ../data-part-03/notebook-1.txt\n",
      "```\n",
      "\n",
      "The output should be the save as in version 2."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Section 9 - Create Regex Pattern for 2nd Notebook\n",
      "\n",
      "Now that we have our code organized, let's look at the pattern for site 2. First, open `notebook-2.txt` and copy the data lines.\n",
      "\n",
      "### Back to the online tool!\n",
      "\n",
      "Our old pattern no longer works, so we'll need to create a new one. One obvious difference: this site uses a backslash for a delimiter instead of a tab character. Let's isolate the first field, the site:\n",
      "\n",
      "```\n",
      "^([\\w|\\s]+)/\n",
      "```\n",
      "\n",
      "This part is the same as the first file: starting at the beginning of a line, match one or more word or space characters. Now, let's tackle the new date format:\n",
      "\n",
      "```\n",
      "^([\\w|\\s]+)/(\\w+)\\s*(\\d+),?\\s*(20\\d\\d)\n",
      "```\n",
      "\n",
      "Breaking this down. After the \"/\" delimiter, there should be one or more word characters for the month name. Then, maybe there's a space (zero or more). Next, we should find one or more digits for the day of the month, followed by an optional comma and maybe some more space (zero or more). Finally, we should find a 4 digit year between 2000 and 2099.\n",
      "\n",
      "This works, so let's add the final delimiter and get our value:\n",
      "\n",
      "```\n",
      "^([\\w|\\s]+)/(\\w+)\\s*(\\d+),?\\s*(20\\d\\d)/(\\d+\\.?\\d*)$\n",
      "```\n",
      "\n",
      "The value regex is also the same as the first file. Looks like this works. Let's plug it into our script as a new pattern, and run it against both files."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Section 10 - Regex Script Version 4\n",
      "\n",
      "We need to modify our function to handle more than one pattern. Ideally, we'd like to create a solution that is easy to modify in case we ever run across a file with yet another variation in the data format.\n",
      "\n",
      "** Note the match order is different for our new pattern **\n",
      "\n",
      "So, we need to associate a regex with the order of the fields that the regex matches against. Anyone have a guess as to what data structure we could use?\n",
      "\n",
      "Let's try a dictionary where the key is the regular expression string, and the value is a list containing the order of the fields we want."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import fileinput\n",
      "import re\n",
      "\n",
      "def parse_record(record_string):\n",
      "    '''\n",
      "    Return formatted data record as (Y, M, D, site, value) or None\n",
      "    '''\n",
      "\n",
      "    # Save patterns in a dictionary. For each pattern:\n",
      "    #   - key is the regex string\n",
      "    #   - value is the field order in a list. \n",
      "    # The value list field order is:\n",
      "    #   - year, month, day, site, value\n",
      "    patterns = {\n",
      "        '^(\\w+)\\s+(20\\d\\d)-(\\d\\d)-(\\d\\d)\\s+(\\d+\\.?\\d*)$': [2, 3, 4, 1, 5],\n",
      "        '^(\\w+)/(\\w+)\\s*(\\d+),?\\s*(20\\d\\d)/(\\d+\\.?\\d*)$': [4, 2, 3, 1, 5]\n",
      "    }\n",
      "    \n",
      "    for pattern, order_list in patterns.items():\n",
      "        match = re.search(pattern, record_string)\n",
      "        if match:\n",
      "            return [\n",
      "                match.group(order_list[0]),  # year\n",
      "                match.group(order_list[1]),  # month\n",
      "                match.group(order_list[2]),  # day\n",
      "                match.group(order_list[3]),  # site\n",
      "                match.group(order_list[4])   # value\n",
      "            ]\n",
      "    \n",
      "    return None\n",
      "\n",
      "for line in fileinput.input():\n",
      "    if fileinput.isfirstline():\n",
      "        continue\n",
      "\n",
      "    fields = parse_record(line)\n",
      "\n",
      "    if fields:\n",
      "        print \",\".join(fields)\n",
      "    else:\n",
      "        print \"Line {} did not match!\".format(fileinput.lineno())\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Save as `save_the_world_v4.py` and run against both notebook files\n",
      "\n",
      "```\n",
      "python save_the_world_v4.py ../data-part-03/notebook-*\n",
      "```\n",
      "\n",
      "The output should be:\n",
      "\n",
      "```\n",
      "2009,11,17,Baker1,1223.0\n",
      "2010,06,24,Baker1,1122.7\n",
      "2009,07,24,Baker2,2819.0\n",
      "2010,08,25,Baker2,2971.6\n",
      "2011,01,05,Baker1,1410.0\n",
      "2010,09,04,Baker2,4671.6\n",
      "2012,02,25,Baker2,1099.0\n",
      "2013,01,01,Baker1,950.9\n",
      "2012,07,23,Baker1,2000.0\n",
      "2013,08,22,Baker2,3500.4\n",
      "2014,01,02,Baker2,4510.1\n",
      "2010,May,23,Davison,1724.7\n",
      "2010,May,24,Pertwee,2103.8\n",
      "2010,June,19,Davison,1731.9\n",
      "2010,July,6,Davison,2010.7\n",
      "2010,Aug,4,Pertwee,1731.3\n",
      "2010,Sept,3,Pertwee,4981.0\n",
      "2011,June,20,Pertwee,2103.8\n",
      "2011,June,5,Davison,1731.9\n",
      "2011,Dec,14,Davison,2200.4\n",
      "2011,Nov,2,Pertwee,930.1\n",
      "2011,Sept,5,Pertwee,5000.9\n",
      "```\n",
      "\n",
      "So close! We successfully parsed all the data, but notebook 2 has month abbreviations instead of zero-padded numbers."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Section 11 - Regex Script Version 5\n",
      "\n",
      "Technically, the month field in notebook one is a string containing zero-padded numbers. In version 4, let's convert the month abbreviations to numbers. We'll create another dictionary mapping the month abbrevations to the corresponding zero-padded values. Then we can check if our matched month value is in the list of keys.\n",
      "\n",
      "Let's create a version 5:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import fileinput\n",
      "import re\n",
      "\n",
      "def parse_record(record_string):\n",
      "    '''\n",
      "    Return formatted data record as (Y, M, D, site, value) or None\n",
      "    '''\n",
      "\n",
      "    # Save patterns in a dictionary. For each pattern:\n",
      "    #   - key is the regex string\n",
      "    #   - value is the field order in a list. \n",
      "    # The value list field order is:\n",
      "    #   - year, month, day, site, value\n",
      "    patterns = {\n",
      "        '^(\\w+)\\s+(20\\d\\d)-(\\d\\d)-(\\d\\d)\\s+(\\d+\\.?\\d*)$': [2, 3, 4, 1, 5],\n",
      "        '^(\\w+)/(\\w+)\\s*(\\d+),?\\s*(20\\d\\d)/(\\d+\\.?\\d*)$': [4, 2, 3, 1, 5]\n",
      "    }\n",
      "    \n",
      "    month_conversions = {\n",
      "        \"Jan\": '01',\n",
      "        \"Feb\": '02',\n",
      "        \"Mar\": '03',\n",
      "        \"Apr\": '04',\n",
      "        \"May\": '05',\n",
      "        \"Jun\": '06',\n",
      "        \"Jul\": '07',\n",
      "        \"Aug\": '08',\n",
      "        \"Sep\": '09',\n",
      "        \"Oct\": '10',\n",
      "        \"Nov\": '11',\n",
      "        \"Dec\": '12'\n",
      "    }\n",
      "    \n",
      "    for pattern, order_list in patterns.items():\n",
      "        match = re.search(pattern, record_string)\n",
      "        if match:\n",
      "            if match.group(order_list[1])[0:3] in month_conversions.keys():\n",
      "                month = month_conversions[match.group(order_list[1])[0:3]]\n",
      "            else:\n",
      "                month = match.group(order_list[1])\n",
      "            \n",
      "            return [\n",
      "                match.group(order_list[0]),  # year\n",
      "                month,                       # month\n",
      "                match.group(order_list[2]),  # day\n",
      "                match.group(order_list[3]),  # site\n",
      "                match.group(order_list[4])   # value\n",
      "            ]\n",
      "    \n",
      "    return None\n",
      "\n",
      "for line in fileinput.input():\n",
      "    if fileinput.isfirstline():\n",
      "        continue\n",
      "\n",
      "    fields = parse_record(line)\n",
      "\n",
      "    if fields:\n",
      "        print \",\".join(fields)\n",
      "    else:\n",
      "        print \"Line {} did not match!\".format(fileinput.lineno())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Save as `save_the_world_v5.py` and run against both notebook files\n",
      "\n",
      "```\n",
      "python save_the_world_v5.py ../data-part-03/notebook-*\n",
      "```\n",
      "\n",
      "The output should be:\n",
      "\n",
      "```\n",
      "2009,11,17,Baker1,1223.0\n",
      "2010,06,24,Baker1,1122.7\n",
      "2009,07,24,Baker2,2819.0\n",
      "2010,08,25,Baker2,2971.6\n",
      "2011,01,05,Baker1,1410.0\n",
      "2010,09,04,Baker2,4671.6\n",
      "2012,02,25,Baker2,1099.0\n",
      "2013,01,01,Baker1,950.9\n",
      "2012,07,23,Baker1,2000.0\n",
      "2013,08,22,Baker2,3500.4\n",
      "2014,01,02,Baker2,4510.1\n",
      "2010,05,23,Davison,1724.7\n",
      "2010,05,24,Pertwee,2103.8\n",
      "2010,06,19,Davison,1731.9\n",
      "2010,07,6,Davison,2010.7\n",
      "2010,08,4,Pertwee,1731.3\n",
      "2010,09,3,Pertwee,4981.0\n",
      "2011,06,20,Pertwee,2103.8\n",
      "2011,06,5,Davison,1731.9\n",
      "2011,12,14,Davison,2200.4\n",
      "2011,11,2,Pertwee,930.1\n",
      "2011,09,5,Pertwee,5000.9\n",
      "```\n",
      "\n",
      "We've done it! We could easily pipe this to a file, but Python can create files too!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Section 12 - Regex Script Version 6 (FINAL)\n",
      "\n",
      "All that's left is to save our nicely formatted data to a file. Let's create our final version:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import fileinput\n",
      "import re\n",
      "\n",
      "def parse_record(record_string):\n",
      "    '''\n",
      "    Return formatted data record as (Y, M, D, site, value) or None\n",
      "    '''\n",
      "    \n",
      "    # Save patterns in a dictionary. For each pattern:\n",
      "    #   - key is the regex string\n",
      "    #   - value is the field order in a list. \n",
      "    # The value list field order is:\n",
      "    #   - year, month, day, site, value\n",
      "    patterns = {\n",
      "        '^(\\w+)\\s+(20\\d\\d)-(\\d\\d)-(\\d\\d)\\s+(\\d+\\.?\\d*)$': [2, 3, 4, 1, 5],\n",
      "        '^(\\w+)/(\\w+)\\s*(\\d+),?\\s*(20\\d\\d)/(\\d+\\.?\\d*)$': [4, 2, 3, 1, 5]\n",
      "    }\n",
      "    \n",
      "    month_conversions = {\n",
      "        \"Jan\": '01',\n",
      "        \"Feb\": '02',\n",
      "        \"Mar\": '03',\n",
      "        \"Apr\": '04',\n",
      "        \"May\": '05',\n",
      "        \"Jun\": '06',\n",
      "        \"Jul\": '07',\n",
      "        \"Aug\": '08',\n",
      "        \"Sep\": '09',\n",
      "        \"Oct\": '10',\n",
      "        \"Nov\": '11',\n",
      "        \"Dec\": '12'\n",
      "    }\n",
      "    \n",
      "    for pattern, order_list in patterns.items():\n",
      "        match = re.search(pattern, record_string)\n",
      "        if match:\n",
      "            if match.group(order_list[1])[0:3] in month_conversions.keys():\n",
      "                month = month_conversions[match.group(order_list[1])[0:3]]\n",
      "            else:\n",
      "                month = match.group(order_list[1])\n",
      "            \n",
      "            return [\n",
      "                match.group(order_list[0]),  # year\n",
      "                month,                       # month\n",
      "                match.group(order_list[2]),  # day\n",
      "                match.group(order_list[3]),  # site\n",
      "                match.group(order_list[4])   # value\n",
      "            ]\n",
      "    \n",
      "    return None\n",
      "\n",
      "output = open('output.csv', 'w')\n",
      "\n",
      "for line in fileinput.input():\n",
      "    if fileinput.isfirstline():\n",
      "        continue\n",
      "    \n",
      "    fields = parse_record(line)\n",
      "    \n",
      "    if fields:\n",
      "        formatted_line = ','.join(fields)\n",
      "        output.write(formatted_line + '\\n')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Save as `save_the_world_v6.py` and run against both notebook files\n",
      "\n",
      "```\n",
      "python save_the_world_v6.py ../data-part-03/notebook-*\n",
      "```\n",
      "\n",
      "There shouldn't be any output on STDOUT if everything parses ok. There should be a new file called `output.csv`. Lets run `cat` on the file and see if it contains all our data:\n",
      "\n",
      "```\n",
      "$ cat output.csv \n",
      "2009,11,17,Baker1,1223.0\n",
      "2010,06,24,Baker1,1122.7\n",
      "2009,07,24,Baker2,2819.0\n",
      "2010,08,25,Baker2,2971.6\n",
      "2011,01,05,Baker1,1410.0\n",
      "2010,09,04,Baker2,4671.6\n",
      "2012,02,25,Baker2,1099.0\n",
      "2013,01,01,Baker1,950.9\n",
      "2012,07,23,Baker1,2000.0\n",
      "2013,08,22,Baker2,3500.4\n",
      "2014,01,02,Baker2,4510.1\n",
      "2010,05,23,Davison,1724.7\n",
      "2010,05,24,Pertwee,2103.8\n",
      "2010,06,19,Davison,1731.9\n",
      "2010,07,6,Davison,2010.7\n",
      "2010,08,4,Pertwee,1731.3\n",
      "2010,09,3,Pertwee,4981.0\n",
      "2011,06,20,Pertwee,2103.8\n",
      "2011,06,5,Davison,1731.9\n",
      "2011,12,14,Davison,2200.4\n",
      "2011,11,2,Pertwee,930.1\n",
      "2011,09,5,Pertwee,5000.9\n",
      "```"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}